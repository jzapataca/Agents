{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aoroz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aoroz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz \n",
    "import docx\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import textstat\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.units import inch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tkinter import filedialog\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la API de Gemini, en donde dice API_KEY colocar la API de Gemini. Se obtiene en el siguiente link\n",
    "https://aistudio.google.com/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la API key desde .env\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que al final crearemos un orquestador para todo el procedimiento, empezamos con las funciones.\n",
    "\n",
    "La primera es para pedirle al usuario el temario de la asignatura a la que se le va generar el material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_file():\n",
    "    while True:\n",
    "        print(\"\\nPlease enter the path to a PDF, DOCX, or TXT file:\")\n",
    "        file_path = input().strip()\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"Error: File does not exist.\")\n",
    "            continue\n",
    "            \n",
    "        # Get file extension\n",
    "        _, extension = os.path.splitext(file_path)\n",
    "        extension = extension.lower()\n",
    "        \n",
    "        # Validate file extension\n",
    "        valid_extensions = ['.pdf', '.docx', '.txt']\n",
    "        if extension not in valid_extensions:\n",
    "            print(f\"Error: File must be one of these types: {', '.join(valid_extensions)}\")\n",
    "            continue\n",
    "            \n",
    "        return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se realiza la extracción del contenido según el tipo de archivo que se haya cargado, en este caso puede ser PDF, DOCX o TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extrae texto de un archivo PDF.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        return \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"Extrae texto de un archivo DOCX.\"\"\"\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_txt(txt_path):\n",
    "    \"\"\"Lee texto desde un archivo TXT.\"\"\"\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "def extract_text(file_path):\n",
    "    \"\"\"Detecta el tipo de archivo y extrae su contenido.\"\"\"\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    if ext.lower() == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif ext.lower() == \".docx\":\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif ext.lower() == \".txt\":\n",
    "        return extract_text_from_txt(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Formato de archivo no soportado. Usa PDF, DOCX o TXT.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la petición al modelo de Gemini para realizar el material de estudio mediante 5 prompts, los cuales le piden:\n",
    "- Notas de clase\n",
    "- Problemas\n",
    "- Preguntas de discusión\n",
    "- Objetivos de aprendizaje\n",
    "- Lecturas sugeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content(prompt):\n",
    "    \"\"\"Genera contenido con Gemini a partir de un prompt.\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def generate_study_materials(course_text):\n",
    "    \"\"\"Genera notas de clase, problemas, preguntas, objetivos y lecturas con Gemini.\"\"\"\n",
    "    \n",
    "    prompts = {\n",
    "        \"notas_clase\": f\"Genera notas de clase detalladas basadas en este programa de curso:\\n{course_text}\",\n",
    "        \"problemas_practica\": f\"Genera problemas de práctica con soluciones basados en este programa de curso:\\n{course_text}\",\n",
    "        \"preguntas_discusion\": f\"Genera preguntas para discusión relacionadas con los temas de este programa de curso:\\n{course_text}\",\n",
    "        \"objetivos_aprendizaje\": f\"Genera objetivos de aprendizaje detallados basados en este programa de curso:\\n{course_text}\",\n",
    "        \"lecturas_sugeridas\": f\"Sugiere lecturas y recursos académicos basados en este programa de curso:\\n{course_text}\"\n",
    "    }\n",
    "\n",
    "    materials = {key: generate_content(prompt) for key, prompt in prompts.items()}\n",
    "    \n",
    "    return materials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el PDF que contiene la respuesta del LLM, a este PDF se le organizan cosas como las negritas, los bloques de código, entre otros elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estilo para bloques de código\n",
    "code_style = ParagraphStyle(\n",
    "    \"CodeStyle\",\n",
    "    fontName=\"Courier\",\n",
    "    fontSize=10,\n",
    "    leading=12,\n",
    "    spaceBefore=5,\n",
    "    spaceAfter=5,\n",
    "    backColor=\"#F5F5F5\"  # Fondo gris claro para destacar bloques de código\n",
    ")\n",
    "\n",
    "def format_text(text):\n",
    "    \"\"\"Convierte **negrita** en <b>negrita</b>.\"\"\"\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'<b>\\1</b>', text)  # Negritas\n",
    "    return text\n",
    "\n",
    "def process_sections(text):\n",
    "    \"\"\"Detecta código dentro de ``` y lo separa del texto normal.\"\"\"\n",
    "    sections = re.split(r\"```\", text)\n",
    "    formatted_content = []\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        if i % 2 == 0:\n",
    "            formatted_content.append((\"text\", format_text(section.strip())))  # Texto normal\n",
    "        else:\n",
    "            # Formatear código correctamente con saltos de línea\n",
    "            formatted_code = section.strip().replace(\"\\n\", \"<br/>\")  # Saltos de línea\n",
    "            formatted_code = formatted_code.replace(\" \", \"&nbsp;\")   # Mantener espacios\n",
    "            formatted_content.append((\"code\", formatted_code))\n",
    "    \n",
    "    return formatted_content\n",
    "\n",
    "def generate_pdf(materials, output_filename):\n",
    "    \"\"\"Genera un PDF con materiales didácticos formateados correctamente.\"\"\"\n",
    "    output_filename = \"../\"+output_filename+\".pdf\"\n",
    "    doc = SimpleDocTemplate(output_filename, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    content = []\n",
    "\n",
    "    # Agregar título principal\n",
    "    title = Paragraph(\"<b>Material Didáctico Generado</b>\", styles[\"Title\"])\n",
    "    content.append(title)\n",
    "    content.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    for section, text in materials.items():\n",
    "        # Agregar título de sección\n",
    "        section_title = Paragraph(f\"<b>{section.replace('_', ' ').title()}</b>\", styles[\"Heading2\"])\n",
    "        content.append(section_title)\n",
    "        content.append(Spacer(1, 0.15 * inch))\n",
    "\n",
    "        # Procesar bloques de texto y código\n",
    "        formatted_sections = process_sections(text)\n",
    "        for section_type, section_content in formatted_sections:\n",
    "            if section_type == \"text\":\n",
    "                paragraphs = section_content.split(\"\\n\\n\")  # Separar párrafos\n",
    "                for paragraph in paragraphs:\n",
    "                    content.append(Paragraph(paragraph, styles[\"BodyText\"]))\n",
    "                    content.append(Spacer(1, 0.1 * inch))\n",
    "            elif section_type == \"code\":\n",
    "                # Formato de código con Courier y saltos de línea\n",
    "                content.append(Paragraph(f'<font face=\"Courier\">{section_content}</font>', code_style))\n",
    "                content.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "    # Generar PDF\n",
    "    doc.build(content)\n",
    "    print(f\"✅ PDF generado correctamente: {output_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar stopwords en español\n",
    "stopwords_es = stopwords.words('spanish')\n",
    "\n",
    "# Cargar modelo de embeddings para similitud semántica\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def concatenar_material(material):\n",
    "    \"\"\"\n",
    "    Convierte un diccionario con materiales de clase en un solo string.\n",
    "    \"\"\"\n",
    "    if isinstance(material, dict):\n",
    "        return \" \".join(str(v) for v in material.values())\n",
    "    return str(material)\n",
    "\n",
    "def calcular_relevancia(temario, material):\n",
    "    \"\"\"\n",
    "    Calcula la similitud coseno entre el temario y el material generado usando TF-IDF.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords_es)\n",
    "    tfidf_matrix = vectorizer.fit_transform([temario, material])\n",
    "    similitud = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    return similitud\n",
    "\n",
    "def calcular_consistencia(seccion1, seccion2):\n",
    "    \"\"\"\n",
    "    Mide la similitud semántica entre dos secciones del material.\n",
    "    \"\"\"\n",
    "    emb1 = model.encode(seccion1, convert_to_tensor=True)\n",
    "    emb2 = model.encode(seccion2, convert_to_tensor=True)\n",
    "    similitud = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "    return similitud\n",
    "\n",
    "def calcular_legibilidad(texto):\n",
    "    \"\"\"\n",
    "    Calcula la puntuación Flesch-Kincaid para evaluar la legibilidad del texto.\n",
    "    \"\"\"\n",
    "    return textstat.flesch_kincaid_grade(texto)\n",
    "\n",
    "def analizar_terminologia(temario, material):\n",
    "    \"\"\"\n",
    "    Evalúa la presencia de términos clave del temario en el material generado.\n",
    "    \"\"\"\n",
    "    palabras_temario = set(nltk.word_tokenize(temario.lower()))\n",
    "    palabras_material = Counter(nltk.word_tokenize(material.lower()))\n",
    "    cobertura = sum(palabras_material[p] for p in palabras_temario if p in palabras_material) / len(palabras_temario)\n",
    "    return cobertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_material_didactico(temario, material):\n",
    "    \"\"\"\n",
    "    Evalúa la calidad de un material didáctico generado.\n",
    "    \"\"\"\n",
    "    material_texto = concatenar_material(material)\n",
    "    relevancia = calcular_relevancia(temario, material_texto)\n",
    "    legibilidad = calcular_legibilidad(material_texto)\n",
    "    terminologia = analizar_terminologia(temario, material_texto)\n",
    "    return relevancia, legibilidad, terminologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_file():\n",
    "    \"\"\"\n",
    "    Opens a file dialog to select PDF, DOCX, or TXT files.\n",
    "    Returns the selected file path or None if canceled.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create and show the root window\n",
    "    root = tk.Tk()\n",
    "    root.attributes('-topmost', True)  # Make dialog appear on top\n",
    "    \n",
    "    # Define allowed file types\n",
    "    filetypes = (\n",
    "        ('PDF files', '*.pdf'),\n",
    "        ('Word documents', '*.docx'),\n",
    "        ('Text files', '*.txt')\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Open file dialog\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            parent=root,\n",
    "            title='Select a file',\n",
    "            filetypes=filetypes\n",
    "        )\n",
    "        \n",
    "        # Destroy the root window after selection\n",
    "        root.destroy()\n",
    "        \n",
    "        if file_path:\n",
    "            return file_path\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        root.destroy()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_material_didactico(nombre_archivo):\n",
    "    \"\"\"\n",
    "    Genera materiales didácticos basados en un temario y evalúa su calidad.\n",
    "    \"\"\"\n",
    "    archivo = select_file()\n",
    "    temario = extract_text(archivo)\n",
    "    materiales = generate_study_materials(temario)\n",
    "    evaluaciones = evaluar_material_didactico(temario, materiales)\n",
    "    generate_pdf(materiales, nombre_archivo)\n",
    "    print(f\"\\n=== Evaluación del Material Didáctico según el temario otorgado ===\")\n",
    "    print(f\"Relevancia: {evaluaciones[0]:.2f}\")\n",
    "    print(f\"Legibilidad: {evaluaciones[1]:.2f}\")\n",
    "    print(f\"Terminología: {evaluaciones[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF generado correctamente: material_fp.pdf\n",
      "\n",
      "=== Evaluación del Material Didáctico ===\n",
      "Relevancia: 0.47\n",
      "Legibilidad: 10.90\n",
      "Terminología: 21.77\n"
     ]
    }
   ],
   "source": [
    "generar_material_didactico(input(\"Nombre del archivo que vas a generar: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
